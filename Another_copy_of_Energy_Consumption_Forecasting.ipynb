{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdQNwbJS69Cei4jhdjNhRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlajideFemi/Carbon-Footprint/blob/main/Another_copy_of_Energy_Consumption_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Energy Consumption Forecasting"
      ],
      "metadata": {
        "id": "8-HqIc-UJejw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><b>Problem Statement</b></p>\n",
        "\n",
        "The objective is to forecast electricity demand over future time periods in order to support operational planning, cost control, and infrastructure resilience.\n",
        "Accurate demand forecasting is critical because electricity systems must balance supply and demand in real time. Over- or under-estimation can result in service disruption, increased costs, or system instability.\n"
      ],
      "metadata": {
        "id": "QLgqddNqJoct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load demand\n",
        "demand = pd.read_csv(\"historic_demand_2009_2024.csv\")\n",
        "\n",
        "# Convert 'settlement_date' to datetime and create 'timestamp'\n",
        "demand[\"settlement_date\"] = pd.to_datetime(demand[\"settlement_date\"])\n",
        "demand[\"timestamp\"] = (\n",
        "    demand[\"settlement_date\"]\n",
        "    + pd.to_timedelta((demand[\"settlement_period\"] - 1) * 30, unit=\"min\")\n",
        ")\n",
        "\n",
        "# Set timestamp as index and sort\n",
        "demand = demand.set_index(\"timestamp\").sort_index()\n",
        "\n",
        "# Drop original date and period columns along with 'Unnamed: 0'\n",
        "columns_to_drop = ['Unnamed: 0', 'settlement_date', 'settlement_period']\n",
        "demand = demand.drop(columns=[col for col in columns_to_drop if col in demand.columns])\n",
        "\n",
        "# Load weather (if applicable, commented out as per original notebook)\n",
        "#weather = pd.read_csv(\"uk_weather.csv\", parse_dates=[\"date\"])"
      ],
      "metadata": {
        "id": "LmCcJV-0KKI1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand.head()"
      ],
      "metadata": {
        "id": "EEvTz6_QmWdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "87d83d45-8d24-4a9d-b881-28b7be93ba2b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_interactive_table_hint_button.py:178: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
            "  df_html=dataframe._repr_html_(),  # pylint: disable=protected-access\n",
            "/usr/local/lib/python3.12/dist-packages/google/colab/_interactive_table_hint_button.py:178: FutureWarning: DatetimeIndex.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
            "  df_html=dataframe._repr_html_(),  # pylint: disable=protected-access\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        nd    tsd  england_wales_demand  \\\n",
              "timestamp                                                 \n",
              "2009-01-01 00:00:00  37910  38704                 33939   \n",
              "2009-01-01 00:30:00  38047  38964                 34072   \n",
              "2009-01-01 01:00:00  37380  38651                 33615   \n",
              "2009-01-01 01:30:00  36426  37775                 32526   \n",
              "2009-01-01 02:00:00  35687  37298                 31877   \n",
              "\n",
              "                     embedded_wind_generation  embedded_wind_capacity  \\\n",
              "timestamp                                                               \n",
              "2009-01-01 00:00:00                        54                    1403   \n",
              "2009-01-01 00:30:00                        53                    1403   \n",
              "2009-01-01 01:00:00                        53                    1403   \n",
              "2009-01-01 01:30:00                        50                    1403   \n",
              "2009-01-01 02:00:00                        50                    1403   \n",
              "\n",
              "                     embedded_solar_generation  embedded_solar_capacity  \\\n",
              "timestamp                                                                 \n",
              "2009-01-01 00:00:00                          0                        0   \n",
              "2009-01-01 00:30:00                          0                        0   \n",
              "2009-01-01 01:00:00                          0                        0   \n",
              "2009-01-01 01:30:00                          0                        0   \n",
              "2009-01-01 02:00:00                          0                        0   \n",
              "\n",
              "                     non_bm_stor  pump_storage_pumping  ifa_flow  ...  \\\n",
              "timestamp                                                         ...   \n",
              "2009-01-01 00:00:00            0                    33      2002  ...   \n",
              "2009-01-01 00:30:00            0                   157      2002  ...   \n",
              "2009-01-01 01:00:00            0                   511      2002  ...   \n",
              "2009-01-01 01:30:00            0                   589      1772  ...   \n",
              "2009-01-01 02:00:00            0                   851      1753  ...   \n",
              "\n",
              "                     britned_flow  moyle_flow  east_west_flow  nemo_flow  \\\n",
              "timestamp                                                                  \n",
              "2009-01-01 00:00:00             0        -161               0          0   \n",
              "2009-01-01 00:30:00             0        -160               0          0   \n",
              "2009-01-01 01:00:00             0        -160               0          0   \n",
              "2009-01-01 01:30:00             0        -160               0          0   \n",
              "2009-01-01 02:00:00             0        -160               0          0   \n",
              "\n",
              "                     nsl_flow  eleclink_flow  scottish_transfer  viking_flow  \\\n",
              "timestamp                                                                      \n",
              "2009-01-01 00:00:00       NaN            NaN                NaN          NaN   \n",
              "2009-01-01 00:30:00       NaN            NaN                NaN          NaN   \n",
              "2009-01-01 01:00:00       NaN            NaN                NaN          NaN   \n",
              "2009-01-01 01:30:00       NaN            NaN                NaN          NaN   \n",
              "2009-01-01 02:00:00       NaN            NaN                NaN          NaN   \n",
              "\n",
              "                     greenlink_flow  is_holiday  \n",
              "timestamp                                        \n",
              "2009-01-01 00:00:00             NaN           1  \n",
              "2009-01-01 00:30:00             NaN           1  \n",
              "2009-01-01 01:00:00             NaN           1  \n",
              "2009-01-01 01:30:00             NaN           1  \n",
              "2009-01-01 02:00:00             NaN           1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2dcd1e3-018f-4ed8-b1ab-8071bc200655\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nd</th>\n",
              "      <th>tsd</th>\n",
              "      <th>england_wales_demand</th>\n",
              "      <th>embedded_wind_generation</th>\n",
              "      <th>embedded_wind_capacity</th>\n",
              "      <th>embedded_solar_generation</th>\n",
              "      <th>embedded_solar_capacity</th>\n",
              "      <th>non_bm_stor</th>\n",
              "      <th>pump_storage_pumping</th>\n",
              "      <th>ifa_flow</th>\n",
              "      <th>...</th>\n",
              "      <th>britned_flow</th>\n",
              "      <th>moyle_flow</th>\n",
              "      <th>east_west_flow</th>\n",
              "      <th>nemo_flow</th>\n",
              "      <th>nsl_flow</th>\n",
              "      <th>eleclink_flow</th>\n",
              "      <th>scottish_transfer</th>\n",
              "      <th>viking_flow</th>\n",
              "      <th>greenlink_flow</th>\n",
              "      <th>is_holiday</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-01-01 00:00:00</th>\n",
              "      <td>37910</td>\n",
              "      <td>38704</td>\n",
              "      <td>33939</td>\n",
              "      <td>54</td>\n",
              "      <td>1403</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>2002</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-161</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-01-01 00:30:00</th>\n",
              "      <td>38047</td>\n",
              "      <td>38964</td>\n",
              "      <td>34072</td>\n",
              "      <td>53</td>\n",
              "      <td>1403</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>157</td>\n",
              "      <td>2002</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-160</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-01-01 01:00:00</th>\n",
              "      <td>37380</td>\n",
              "      <td>38651</td>\n",
              "      <td>33615</td>\n",
              "      <td>53</td>\n",
              "      <td>1403</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>511</td>\n",
              "      <td>2002</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-160</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-01-01 01:30:00</th>\n",
              "      <td>36426</td>\n",
              "      <td>37775</td>\n",
              "      <td>32526</td>\n",
              "      <td>50</td>\n",
              "      <td>1403</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>589</td>\n",
              "      <td>1772</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-160</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-01-01 02:00:00</th>\n",
              "      <td>35687</td>\n",
              "      <td>37298</td>\n",
              "      <td>31877</td>\n",
              "      <td>50</td>\n",
              "      <td>1403</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>851</td>\n",
              "      <td>1753</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-160</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2dcd1e3-018f-4ed8-b1ab-8071bc200655')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2dcd1e3-018f-4ed8-b1ab-8071bc200655 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2dcd1e3-018f-4ed8-b1ab-8071bc200655');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "demand"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demand.dtypes"
      ],
      "metadata": {
        "id": "3XIU-x5smpLS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "aa82c034-dd23-495f-eee1-2d6cfbf58f2f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_reprs.py:211: FutureWarning: RangeIndex.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
            "  series_as_table_html = series.to_frame()._repr_html_()  # pylint: disable=protected-access\n",
            "/usr/local/lib/python3.12/dist-packages/google/colab/_reprs.py:211: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
            "  series_as_table_html = series.to_frame()._repr_html_()  # pylint: disable=protected-access\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nd                             int64\n",
              "tsd                            int64\n",
              "england_wales_demand           int64\n",
              "embedded_wind_generation       int64\n",
              "embedded_wind_capacity         int64\n",
              "embedded_solar_generation      int64\n",
              "embedded_solar_capacity        int64\n",
              "non_bm_stor                    int64\n",
              "pump_storage_pumping           int64\n",
              "ifa_flow                       int64\n",
              "ifa2_flow                      int64\n",
              "britned_flow                   int64\n",
              "moyle_flow                     int64\n",
              "east_west_flow                 int64\n",
              "nemo_flow                      int64\n",
              "nsl_flow                     float64\n",
              "eleclink_flow                float64\n",
              "scottish_transfer            float64\n",
              "viking_flow                  float64\n",
              "greenlink_flow               float64\n",
              "is_holiday                     int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>nd</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tsd</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>england_wales_demand</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embedded_wind_generation</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embedded_wind_capacity</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embedded_solar_generation</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embedded_solar_capacity</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>non_bm_stor</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pump_storage_pumping</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ifa_flow</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ifa2_flow</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>britned_flow</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moyle_flow</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>east_west_flow</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nemo_flow</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nsl_flow</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eleclink_flow</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scottish_transfer</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>viking_flow</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>greenlink_flow</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_holiday</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demand.shape"
      ],
      "metadata": {
        "id": "bkcbFJM4myJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e601225d-4379-4871-a17b-c4739b648b12"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(279264, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demand.describe()"
      ],
      "metadata": {
        "id": "K2lOhQILnWB9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "7cbb8970-f7bb-4536-975e-41a4fdee3b2d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_interactive_table_hint_button.py:178: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
            "  df_html=dataframe._repr_html_(),  # pylint: disable=protected-access\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  nd            tsd  england_wales_demand  \\\n",
              "count  279264.000000  279264.000000         279264.000000   \n",
              "mean    31186.565042   32627.843779          28389.002868   \n",
              "std      7827.270027    7710.008440           7087.628201   \n",
              "min     13367.000000       0.000000              0.000000   \n",
              "25%     24908.000000   26582.000000          22677.000000   \n",
              "50%     30495.000000   31782.000000          27756.000000   \n",
              "75%     36913.000000   38096.000000          33615.000000   \n",
              "max     59095.000000   60147.000000          53325.000000   \n",
              "\n",
              "       embedded_wind_generation  embedded_wind_capacity  \\\n",
              "count             279264.000000           279264.000000   \n",
              "mean                1270.098774             4447.695772   \n",
              "std                  966.304596             1957.216235   \n",
              "min                    0.000000             1403.000000   \n",
              "25%                  551.000000             2102.000000   \n",
              "50%                 1016.000000             4831.000000   \n",
              "75%                 1726.000000             6527.000000   \n",
              "max                 5930.000000             6622.000000   \n",
              "\n",
              "       embedded_solar_generation  embedded_solar_capacity    non_bm_stor  \\\n",
              "count              279264.000000            279264.000000  279264.000000   \n",
              "mean                  878.177069              8685.163430       6.654220   \n",
              "std                  1709.142408              5875.188186      39.150778   \n",
              "min                     0.000000                 0.000000     -24.000000   \n",
              "25%                     0.000000              2028.000000       0.000000   \n",
              "50%                     0.000000             11503.000000       0.000000   \n",
              "75%                   883.000000             13080.000000       0.000000   \n",
              "max                 11224.000000             17197.000000     893.000000   \n",
              "\n",
              "       pump_storage_pumping       ifa_flow  ...   britned_flow     moyle_flow  \\\n",
              "count         279264.000000  279264.000000  ...  279264.000000  279264.000000   \n",
              "mean             304.734674     926.205544  ...     503.999842    -125.610222   \n",
              "std              528.372063    1067.861437  ...     541.490053     230.333166   \n",
              "min                0.000000   -2056.000000  ...   -1215.000000    -505.000000   \n",
              "25%                8.000000     273.000000  ...       0.000000    -304.000000   \n",
              "50%               11.000000    1178.000000  ...     725.000000    -149.000000   \n",
              "75%              368.000000    1891.000000  ...     994.000000      24.000000   \n",
              "max             2019.000000    2066.000000  ...    1143.000000     499.000000   \n",
              "\n",
              "       east_west_flow      nemo_flow       nsl_flow  eleclink_flow  \\\n",
              "count   279264.000000  279264.000000  103968.000000  103968.000000   \n",
              "mean       -50.967919     175.876626     416.582977     114.173929   \n",
              "std        262.941668     421.668169     650.866003     490.431568   \n",
              "min       -585.000000   -1023.000000   -1455.000000   -1028.000000   \n",
              "25%       -208.000000       0.000000       0.000000       0.000000   \n",
              "50%          0.000000       0.000000       0.000000       0.000000   \n",
              "75%          0.000000     332.000000    1095.000000      75.000000   \n",
              "max        504.000000    1033.000000    1401.000000    1002.000000   \n",
              "\n",
              "       scottish_transfer   viking_flow  greenlink_flow     is_holiday  \n",
              "count       33840.000000  33840.000000         16320.0  279264.000000  \n",
              "mean         1704.910757    196.312145             0.0       0.022516  \n",
              "std          1825.530303    562.922278             0.0       0.148356  \n",
              "min         -2851.000000  -1465.000000             0.0       0.000000  \n",
              "25%           267.750000      0.000000             0.0       0.000000  \n",
              "50%          1543.000000      0.000000             0.0       0.000000  \n",
              "75%          3058.000000    512.000000             0.0       0.000000  \n",
              "max          6585.000000   1436.000000             0.0       1.000000  \n",
              "\n",
              "[8 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78429de6-2926-4d7b-a3bb-1fbf0e2766de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nd</th>\n",
              "      <th>tsd</th>\n",
              "      <th>england_wales_demand</th>\n",
              "      <th>embedded_wind_generation</th>\n",
              "      <th>embedded_wind_capacity</th>\n",
              "      <th>embedded_solar_generation</th>\n",
              "      <th>embedded_solar_capacity</th>\n",
              "      <th>non_bm_stor</th>\n",
              "      <th>pump_storage_pumping</th>\n",
              "      <th>ifa_flow</th>\n",
              "      <th>...</th>\n",
              "      <th>britned_flow</th>\n",
              "      <th>moyle_flow</th>\n",
              "      <th>east_west_flow</th>\n",
              "      <th>nemo_flow</th>\n",
              "      <th>nsl_flow</th>\n",
              "      <th>eleclink_flow</th>\n",
              "      <th>scottish_transfer</th>\n",
              "      <th>viking_flow</th>\n",
              "      <th>greenlink_flow</th>\n",
              "      <th>is_holiday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>279264.000000</td>\n",
              "      <td>103968.000000</td>\n",
              "      <td>103968.000000</td>\n",
              "      <td>33840.000000</td>\n",
              "      <td>33840.000000</td>\n",
              "      <td>16320.0</td>\n",
              "      <td>279264.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>31186.565042</td>\n",
              "      <td>32627.843779</td>\n",
              "      <td>28389.002868</td>\n",
              "      <td>1270.098774</td>\n",
              "      <td>4447.695772</td>\n",
              "      <td>878.177069</td>\n",
              "      <td>8685.163430</td>\n",
              "      <td>6.654220</td>\n",
              "      <td>304.734674</td>\n",
              "      <td>926.205544</td>\n",
              "      <td>...</td>\n",
              "      <td>503.999842</td>\n",
              "      <td>-125.610222</td>\n",
              "      <td>-50.967919</td>\n",
              "      <td>175.876626</td>\n",
              "      <td>416.582977</td>\n",
              "      <td>114.173929</td>\n",
              "      <td>1704.910757</td>\n",
              "      <td>196.312145</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7827.270027</td>\n",
              "      <td>7710.008440</td>\n",
              "      <td>7087.628201</td>\n",
              "      <td>966.304596</td>\n",
              "      <td>1957.216235</td>\n",
              "      <td>1709.142408</td>\n",
              "      <td>5875.188186</td>\n",
              "      <td>39.150778</td>\n",
              "      <td>528.372063</td>\n",
              "      <td>1067.861437</td>\n",
              "      <td>...</td>\n",
              "      <td>541.490053</td>\n",
              "      <td>230.333166</td>\n",
              "      <td>262.941668</td>\n",
              "      <td>421.668169</td>\n",
              "      <td>650.866003</td>\n",
              "      <td>490.431568</td>\n",
              "      <td>1825.530303</td>\n",
              "      <td>562.922278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.148356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13367.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1403.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2056.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-1215.000000</td>\n",
              "      <td>-505.000000</td>\n",
              "      <td>-585.000000</td>\n",
              "      <td>-1023.000000</td>\n",
              "      <td>-1455.000000</td>\n",
              "      <td>-1028.000000</td>\n",
              "      <td>-2851.000000</td>\n",
              "      <td>-1465.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>24908.000000</td>\n",
              "      <td>26582.000000</td>\n",
              "      <td>22677.000000</td>\n",
              "      <td>551.000000</td>\n",
              "      <td>2102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2028.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>273.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-304.000000</td>\n",
              "      <td>-208.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>267.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>30495.000000</td>\n",
              "      <td>31782.000000</td>\n",
              "      <td>27756.000000</td>\n",
              "      <td>1016.000000</td>\n",
              "      <td>4831.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11503.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1178.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>725.000000</td>\n",
              "      <td>-149.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1543.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>36913.000000</td>\n",
              "      <td>38096.000000</td>\n",
              "      <td>33615.000000</td>\n",
              "      <td>1726.000000</td>\n",
              "      <td>6527.000000</td>\n",
              "      <td>883.000000</td>\n",
              "      <td>13080.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>368.000000</td>\n",
              "      <td>1891.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>994.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>332.000000</td>\n",
              "      <td>1095.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>3058.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>59095.000000</td>\n",
              "      <td>60147.000000</td>\n",
              "      <td>53325.000000</td>\n",
              "      <td>5930.000000</td>\n",
              "      <td>6622.000000</td>\n",
              "      <td>11224.000000</td>\n",
              "      <td>17197.000000</td>\n",
              "      <td>893.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>2066.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1143.000000</td>\n",
              "      <td>499.000000</td>\n",
              "      <td>504.000000</td>\n",
              "      <td>1033.000000</td>\n",
              "      <td>1401.000000</td>\n",
              "      <td>1002.000000</td>\n",
              "      <td>6585.000000</td>\n",
              "      <td>1436.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78429de6-2926-4d7b-a3bb-1fbf0e2766de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78429de6-2926-4d7b-a3bb-1fbf0e2766de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78429de6-2926-4d7b-a3bb-1fbf0e2766de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "demand[\"settlement_date\"] = pd.to_datetime(demand[\"settlement_date\"])\n",
        "\n",
        "demand[\"timestamp\"] = (\n",
        "    demand[\"settlement_date\"]\n",
        "    + pd.to_timedelta((demand[\"settlement_period\"] - 1) * 30, unit=\"min\")\n",
        ")\n",
        "\n",
        "demand = demand.set_index(\"timestamp\").sort_index()\n"
      ],
      "metadata": {
        "id": "dwyfL2fyHfzM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "3586d7ab-6f6a-4206-ca11-e68ef1a006e9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'settlement_date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m     _index_shared_docs[\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'settlement_date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1929703843.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdemand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"settlement_date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"settlement_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m demand[\"timestamp\"] = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m         \u001b[0;31m# also raises Exception if object array with NA values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;31m# bool indexer is indexing along rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0minput\u001b[0m \u001b[0mto\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m \u001b[0mto\u001b[0m \u001b[0malign\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m         \u001b[0mcurrent\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'settlement_date'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demand[\"england_wales_demand\"].plot(figsize=(15,5))\n"
      ],
      "metadata": {
        "id": "8bHI81TqITwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand[\"england_wales_demand\"].describe()\n"
      ],
      "metadata": {
        "id": "3sdlpP2QK8BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand[\"bad_reading\"] = demand[\"england_wales_demand\"] < 10000\n"
      ],
      "metadata": {
        "id": "qQ6m1NMzIre8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand[demand[\"bad_reading\"]][\"england_wales_demand\"].count()\n"
      ],
      "metadata": {
        "id": "kElpp9xGLlEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand.loc[demand[\"bad_reading\"], \"england_wales_demand\"] = None\n",
        "demand[\"england_wales_demand\"] = demand[\"england_wales_demand\"].interpolate(method=\"time\")\n"
      ],
      "metadata": {
        "id": "O4bJmH0iL3YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand.loc[\"2022\"][\"england_wales_demand\"].plot(figsize=(15,4))\n"
      ],
      "metadata": {
        "id": "ffxqmKJ-L_l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand[\"hour\"] = demand.index.hour\n",
        "\n",
        "demand.groupby(\"hour\")[\"england_wales_demand\"].mean().plot()\n"
      ],
      "metadata": {
        "id": "JHgnbH2HMEo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand.groupby(demand.index.dayofweek)[\"england_wales_demand\"].mean().plot()\n"
      ],
      "metadata": {
        "id": "MmUABYInMOoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demand[\"month\"] = demand.index.month\n",
        "\n",
        "demand.boxplot(\n",
        "    column=\"england_wales_demand\",\n",
        "    by=\"month\",\n",
        "    figsize=(12,5)\n",
        ")\n"
      ],
      "metadata": {
        "id": "ML7RIkzPMdse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the data\n",
        "demand = pd.read_csv(\"historic_demand_2009_2024.csv\")\n",
        "\n",
        "\n",
        "demand['timestamp'] = pd.to_datetime(demand['settlement_date']) + \\\n",
        "                     pd.to_timedelta((demand['settlement_period'] - 1) * 30, unit='m')\n",
        "\n",
        "# Set timestamp as index\n",
        "demand.set_index('timestamp', inplace=True)\n",
        "demand.sort_index(inplace=True)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "demand = demand.drop(columns=['Unnamed: 0', 'settlement_date', 'settlement_period'])\n",
        "\n",
        "# Check data types\n",
        "print(\"Data types:\")\n",
        "print(demand.dtypes)\n",
        "print(\"\\nMissing values:\")\n",
        "print(demand.isnull().sum())"
      ],
      "metadata": {
        "id": "qcB7KMzqMoS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, recreate the timestamp correctly (based on your data structure)\n",
        "# Assuming settlement_period is 1-48 (half-hourly)\n",
        "demand['timestamp'] = pd.to_datetime(demand['settlement_date']) + \\\n",
        "                     pd.to_timedelta((demand['settlement_period'] - 1) * 30, unit='m')\n",
        "\n",
        "# Set timestamp as index\n",
        "demand.set_index('timestamp', inplace=True)\n",
        "demand.sort_index(inplace=True)\n",
        "\n",
        "# Drop unnecessary columns if they exist\n",
        "columns_to_drop = ['Unnamed: 0', 'settlement_date', 'settlement_period']\n",
        "demand = demand.drop(columns=[col for col in columns_to_drop if col in demand.columns])\n",
        "\n",
        "print(f\"Data shape: {demand.shape}\")\n",
        "print(f\"Date range: {demand.index.min()} to {demand.index.max()}\")\n",
        "print(f\"\\nMissing values summary:\")\n",
        "print(demand.isnull().sum().sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "QnTHBj28eQ_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's see what columns are actually in your DataFrame\n",
        "print(\"Columns in demand DataFrame:\")\n",
        "print(demand.columns.tolist())\n",
        "print(f\"\\nDataFrame shape: {demand.shape}\")\n",
        "\n",
        "# Let's see the first few rows to understand the structure\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(demand.head())"
      ],
      "metadata": {
        "id": "tXr-qYbIe5Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"=== DATA VALIDATION ===\\n\")\n",
        "\n",
        "# Check the date range and frequency\n",
        "print(f\"Data date range: {demand.index.min()} to {demand.index.max()}\")\n",
        "print(f\"Number of periods: {len(demand):,}\")\n",
        "print(f\"Expected periods for 15.5 years (2009-2024): {15.5 * 365.25 * 48:,.0f}\")\n",
        "\n",
        "# Check for missing timestamps\n",
        "full_range = pd.date_range(start=demand.index.min(), end=demand.index.max(), freq='30min')\n",
        "missing_timestamps = full_range.difference(demand.index)\n",
        "print(f\"Missing timestamps: {len(missing_timestamps)}\")\n",
        "\n",
        "# Check data consistency\n",
        "print(f\"\\nData frequency: {pd.infer_freq(demand.index)}\")\n",
        "print(f\"Is index monotonic increasing? {demand.index.is_monotonic_increasing}\")\n",
        "print(f\"Is index unique? {demand.index.is_unique}\")\n",
        "\n",
        "# Check for duplicates\n",
        "duplicates = demand.index.duplicated().sum()\n",
        "print(f\"Duplicate timestamps: {duplicates}\")\n",
        "\n",
        "if duplicates > 0:\n",
        "    print(\"Removing duplicates...\")\n",
        "    demand = demand[~demand.index.duplicated(keep='first')]\n",
        "\n",
        "print(\"\\n=== BASIC STATISTICS ===\")\n",
        "print(f\"Shape after cleaning: {demand.shape}\")"
      ],
      "metadata": {
        "id": "wDYp5IVXgL-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5PCEna_nhhBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_comprehensive_features(df):\n",
        "    \"\"\"\n",
        "    Create comprehensive features for electricity demand forecasting\n",
        "    \"\"\"\n",
        "    df_feat = df.copy()\n",
        "\n",
        "    # 1. Temporal Features\n",
        "    df_feat['hour'] = df_feat.index.hour\n",
        "    df_feat['minute'] = df_feat.index.minute\n",
        "    df_feat['half_hour_period'] = df_feat['hour'] * 2 + (df_feat['minute'] // 30)\n",
        "    df_feat['day_of_week'] = df_feat.index.dayofweek  # Monday=0, Sunday=6\n",
        "    df_feat['day_of_month'] = df_feat.index.day\n",
        "    df_feat['month'] = df_feat.index.month\n",
        "    df_feat['quarter'] = df_feat.index.quarter\n",
        "    df_feat['year'] = df_feat.index.year\n",
        "    df_feat['day_of_year'] = df_feat.index.dayofyear\n",
        "    df_feat['week_of_year'] = df_feat.index.isocalendar().week.astype(int) # Ensure int type\n",
        "\n",
        "    # 2. Calendar Features\n",
        "    df_feat['is_weekend'] = (df_feat['day_of_week'] >= 5).astype(int)\n",
        "    df_feat['is_weekday'] = (df_feat['day_of_week'] < 5).astype(int)\n",
        "    # Ensure 'is_holiday' is treated as numeric, fill NaNs if any after dropping original columns\n",
        "    df_feat['is_holiday'] = df_feat['is_holiday'].fillna(0).astype(int)\n",
        "    df_feat['is_working_day'] = ((df_feat['day_of_week'] < 5) & (df_feat['is_holiday'] == 0)).astype(int)\n",
        "\n",
        "    # Special periods\n",
        "    df_feat['is_morning_peak'] = ((df_feat['hour'] >= 7) & (df_feat['hour'] <= 10)).astype(int)\n",
        "    df_feat['is_evening_peak'] = ((df_feat['hour'] >= 16) & (df_feat['hour'] <= 20)).astype(int)\n",
        "    df_feat['is_overnight'] = ((df_feat['hour'] >= 0) & (df_feat['hour'] <= 5)).astype(int)\n",
        "\n",
        "    # 3. Calculate Net Demand\n",
        "    df_feat['embedded_total_generation'] = df_feat['embedded_wind_generation'] + df_feat['embedded_solar_generation']\n",
        "    df_feat['net_demand'] = df_feat['england_wales_demand'] - df_feat['embedded_total_generation']\n",
        "\n",
        "    # 4. Capacity Factors\n",
        "    # Avoid division by zero\n",
        "    df_feat['wind_capacity_factor'] = np.where(\n",
        "        df_feat['embedded_wind_capacity'] > 0,\n",
        "        df_feat['embedded_wind_generation'] / df_feat['embedded_wind_capacity'],\n",
        "        0\n",
        "    )\n",
        "    df_feat['solar_capacity_factor'] = np.where(\n",
        "        df_feat['embedded_solar_capacity'] > 0,\n",
        "        df_feat['embedded_solar_generation'] / df_feat['embedded_solar_capacity'],\n",
        "        0\n",
        "    )\n",
        "\n",
        "    # 5. Interconnector Analysis\n",
        "    interconnector_cols = [col for col in df.columns if '_flow' in col]\n",
        "\n",
        "    # Fill missing values in interconnectors (new interconnectors commissioned over time)\n",
        "    for col in interconnector_cols:\n",
        "        # Fill forward, then backward, then 0 - using updated syntax\n",
        "        df_feat[col] = df_feat[col].ffill().bfill().fillna(0)\n",
        "\n",
        "    # Calculate interconnector statistics\n",
        "    df_feat['total_interconnector_flow'] = df_feat[interconnector_cols].sum(axis=1)\n",
        "    df_feat['interconnector_imports'] = df_feat[interconnector_cols].clip(lower=0).sum(axis=1)\n",
        "    df_feat['interconnector_exports'] = df_feat[interconnector_cols].clip(upper=0).abs().sum(axis=1)\n",
        "\n",
        "    # 6. Cyclical Encoding for Time Features\n",
        "    # Hour encoding\n",
        "    df_feat['hour_sin'] = np.sin(2 * np.pi * df_feat['hour'] / 24)\n",
        "    df_feat['hour_cos'] = np.cos(2 * np.pi * df_feat['hour'] / 24)\n",
        "\n",
        "    # Day of week encoding\n",
        "    df_feat['day_of_week_sin'] = np.sin(2 * np.pi * df_feat['day_of_week'] / 7)\n",
        "    df_feat['day_of_week_cos'] = np.cos(2 * np.pi * df_feat['day_of_week'] / 7)\n",
        "\n",
        "    # Month encoding\n",
        "    df_feat['month_sin'] = np.sin(2 * np.pi * df_feat['month'] / 12)\n",
        "    df_feat['month_cos'] = np.cos(2 * np.pi * df_feat['month'] / 12)\n",
        "\n",
        "    # 7. Lag Features (Autoregressive)\n",
        "    # Previous periods\n",
        "    df_feat['demand_lag_1'] = df_feat['england_wales_demand'].shift(1)  # Previous half-hour\n",
        "    df_feat['demand_lag_2'] = df_feat['england_wales_demand'].shift(2)  # Previous hour\n",
        "    df_feat['demand_lag_48'] = df_feat['england_wales_demand'].shift(48)  # Previous day same period\n",
        "    df_feat['demand_lag_336'] = df_feat['england_wales_demand'].shift(336)  # Previous week same period\n",
        "\n",
        "    # Net demand lags\n",
        "    df_feat['net_demand_lag_48'] = df_feat['net_demand'].shift(48)\n",
        "\n",
        "    # 8. Rolling Statistics\n",
        "    # Short-term (daily) patterns\n",
        "    df_feat['demand_rolling_24h_mean'] = df_feat['england_wales_demand'].rolling(window=48, min_periods=1).mean()\n",
        "    df_feat['demand_rolling_24h_std'] = df_feat['england_wales_demand'].rolling(window=48, min_periods=1).std()\n",
        "\n",
        "    # Medium-term (weekly) patterns\n",
        "    df_feat['demand_rolling_7d_mean'] = df_feat['england_wales_demand'].rolling(window=336, min_periods=1).mean()\n",
        "    df_feat['demand_rolling_7d_std'] = df_feat['england_wales_demand'].rolling(window=336, min_periods=1).std()\n",
        "\n",
        "    # 9. Rate of Change\n",
        "    df_feat['demand_change_1h'] = df_feat['england_wales_demand'].diff(2)  # Change over 1 hour\n",
        "    df_feat['demand_change_24h'] = df_feat['england_wales_demand'].diff(48)  # Change over 24 hours\n",
        "\n",
        "    # 10. Penetration Rates\n",
        "    df_feat['wind_penetration'] = df_feat['embedded_wind_generation'] / df_feat['england_wales_demand'].replace(0, np.nan)\n",
        "    df_feat['solar_penetration'] = df_feat['embedded_solar_generation'] / df_feat['england_wales_demand'].replace(0, np.nan)\n",
        "    df_feat['total_renewable_penetration'] = (df_feat['embedded_wind_generation'] + df_feat['embedded_solar_generation']) / df_feat['england_wales_demand'].replace(0, np.nan)\n",
        "\n",
        "    # 11. Season Indicators\n",
        "    seasons = {1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
        "               6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Autumn', 10: 'Autumn',\n",
        "               11: 'Autumn', 12: 'Winter'}\n",
        "    df_feat['season'] = df_feat['month'].map(seasons)\n",
        "\n",
        "    # Create dummy variables for seasons\n",
        "    season_dummies = pd.get_dummies(df_feat['season'], prefix='season')\n",
        "    df_feat = pd.concat([df_feat, season_dummies], axis=1)\n",
        "    df_feat.drop('season', axis=1, inplace=True)\n",
        "\n",
        "    # 12. Time of Day Categories\n",
        "    time_of_day = []\n",
        "    for h in df_feat['hour']:\n",
        "        if 0 <= h < 6:\n",
        "            time_of_day.append('Night')\n",
        "        elif 6 <= h < 9:\n",
        "            time_of_day.append('Morning Peak')\n",
        "        elif 9 <= h < 16:\n",
        "            time_of_day.append('Day')\n",
        "        elif 16 <= h < 19:\n",
        "            time_of_day.append('Evening Peak')\n",
        "        else:\n",
        "            time_of_day.append('Evening')\n",
        "    df_feat['time_of_day'] = time_of_day\n",
        "\n",
        "    # Create dummy variables for time of day\n",
        "    time_dummies = pd.get_dummies(df_feat['time_of_day'], prefix='time')\n",
        "    df_feat = pd.concat([df_feat, time_dummies], axis=1)\n",
        "    df_feat.drop('time_of_day', axis=1, inplace=True)\n",
        "\n",
        "    # 13. Fill any remaining NaN values\n",
        "    # Forward fill for lag features, then backward fill - using updated syntax\n",
        "    df_feat = df_feat.ffill().bfill()\n",
        "\n",
        "    # Final check for any remaining NaN\n",
        "    if df_feat.isnull().sum().sum() > 0:\n",
        "        print(f\"Warning: {df_feat.isnull().sum().sum()} NaN values remaining\")\n",
        "        df_feat = df_feat.fillna(0)\n",
        "\n",
        "    # Convert boolean columns created by get_dummies to int\n",
        "    for col in df_feat.columns:\n",
        "        if df_feat[col].dtype == 'bool':\n",
        "            df_feat[col] = df_feat[col].astype(int)\n",
        "\n",
        "    print(f\"Total features created: {len(df_feat.columns)}\")\n",
        "    return df_feat\n",
        "\n",
        "# Apply feature engineering\n",
        "print(\"\\n=== CREATING FEATURES ===\")\n",
        "demand_features = create_comprehensive_features(demand)\n",
        "print(f\"Original columns: {len(demand.columns)}\")\n",
        "print(f\"Enhanced features: {len(demand_features.columns)}\")"
      ],
      "metadata": {
        "id": "1D6Pyawkfk28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_comprehensive_eda(df, sample_year=2023):\n",
        "    \"\"\"\n",
        "    Perform comprehensive exploratory data analysis\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== EXPLORATORY DATA ANALYSIS ===\\n\")\n",
        "\n",
        "    # Basic statistics\n",
        "    print(\"1. BASIC STATISTICS:\")\n",
        "    print(\"-\" * 50)\n",
        "    stats_df = pd.DataFrame({\n",
        "        'Mean': df[['england_wales_demand', 'net_demand', 'embedded_total_generation']].mean(),\n",
        "        'Std': df[['england_wales_demand', 'net_demand', 'embedded_total_generation']].std(),\n",
        "        'Min': df[['england_wales_demand', 'net_demand', 'embedded_total_generation']].min(),\n",
        "        'Max': df[['england_wales_demand', 'net_demand', 'embedded_total_generation']].max(),\n",
        "        'Median': df[['england_wales_demand', 'net_demand', 'embedded_total_generation']].median()\n",
        "    })\n",
        "    print(stats_df.round(2))\n",
        "\n",
        "    # Create visualizations\n",
        "    fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "    # 1. Time series of demand (last year for clarity)\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    last_year = df.loc[f'{sample_year}-01-01':f'{sample_year}-12-31']\n",
        "    ax1.plot(last_year.index, last_year['england_wales_demand'],\n",
        "             linewidth=0.5, alpha=0.7, label='Demand')\n",
        "    ax1.plot(last_year.index, last_year['net_demand'],\n",
        "             linewidth=0.5, alpha=0.7, label='Net Demand', color='orange')\n",
        "    ax1.set_title(f'Demand vs Net Demand ({sample_year})')\n",
        "    ax1.set_ylabel('MW')\n",
        "    ax1.legend(loc='upper right')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Average daily profile\n",
        "    ax2 = plt.subplot(3, 3, 2)\n",
        "    daily_profile = df.groupby(['hour', 'minute'])['england_wales_demand'].mean().reset_index()\n",
        "    daily_profile['time'] = daily_profile['hour'] + daily_profile['minute']/60\n",
        "    ax2.plot(daily_profile['time'], daily_profile['england_wales_demand'], linewidth=2)\n",
        "    ax2.fill_between(daily_profile['time'],\n",
        "                     daily_profile['england_wales_demand'] * 0.95,\n",
        "                     daily_profile['england_wales_demand'] * 1.05,\n",
        "                     alpha=0.3)\n",
        "    ax2.set_title('Average Daily Demand Profile')\n",
        "    ax2.set_xlabel('Hour of Day')\n",
        "    ax2.set_ylabel('Demand (MW)')\n",
        "    ax2.set_xticks(range(0, 25, 4))\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Monthly patterns\n",
        "    ax3 = plt.subplot(3, 3, 3)\n",
        "    monthly_avg = df.groupby(['year', 'month'])['england_wales_demand'].mean().unstack()\n",
        "    monthly_avg.T.plot(ax=ax3, alpha=0.7, linewidth=1)\n",
        "    ax3.set_title('Monthly Average Demand by Year')\n",
        "    ax3.set_xlabel('Month')\n",
        "    ax3.set_ylabel('Average Demand (MW)')\n",
        "    ax3.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Weekly heatmap\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    weekly_heatmap = df.groupby(['day_of_week', 'hour'])['england_wales_demand'].mean().unstack()\n",
        "    im = ax4.imshow(weekly_heatmap, aspect='auto', cmap='YlOrRd')\n",
        "    ax4.set_title('Weekly Demand Pattern Heatmap')\n",
        "    ax4.set_xlabel('Hour of Day')\n",
        "    ax4.set_ylabel('Day of Week')\n",
        "    ax4.set_xticks(range(0, 24, 4))\n",
        "    ax4.set_xticklabels([f'{h:02d}:00' for h in range(0, 24, 4)])\n",
        "    ax4.set_yticks(range(7))\n",
        "    ax4.set_yticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
        "    plt.colorbar(im, ax=ax4, label='Demand (MW)')\n",
        "\n",
        "    # 5. Embedded generation growth\n",
        "    ax5 = plt.subplot(3, 3, 5)\n",
        "    # Ensure only numeric columns are selected for resample().mean()\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    monthly_gen = df[numeric_cols].resample('M').mean()\n",
        "    ax5.plot(monthly_gen.index, monthly_gen['embedded_wind_generation'],\n",
        "             label='Wind', linewidth=2)\n",
        "    ax5.plot(monthly_gen.index, monthly_gen['embedded_solar_generation'],\n",
        "             label='Solar', linewidth=2)\n",
        "    ax5.set_title('Embedded Generation Growth')\n",
        "    ax5.set_xlabel('Year')\n",
        "    ax5.set_ylabel('Average Generation (MW)')\n",
        "    ax5.legend()\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "\n",
        "    # 6. Demand distribution\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    ax6.hist(df['england_wales_demand'], bins=100, edgecolor='black', alpha=0.7)\n",
        "    ax6.axvline(df['england_wales_demand'].mean(), color='red',\n",
        "                linestyle='--', linewidth=2, label=f'Mean: {df[\"england_wales_demand\"].mean():.0f} MW')\n",
        "    ax6.axvline(df['england_wales_demand'].median(), color='green',\n",
        "                linestyle='--', linewidth=2, label=f'Median: {df[\"england_wales_demand\"].median():.0f} MW')\n",
        "    ax6.set_title('Demand Distribution')\n",
        "    ax6.set_xlabel('Demand (MW)')\n",
        "    ax6.set_ylabel('Frequency')\n",
        "    ax6.legend()\n",
        "    ax6.grid(True, alpha=0.3)\n",
        "\n",
        "    # 7. Interconnector usage over time\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    interconnector_cols = [col for col in df.columns if '_flow' in col and 'total' not in col]\n",
        "    # Ensure only numeric columns are selected for resample().sum()\n",
        "    numeric_interconnector_cols = [col for col in interconnector_cols if col in df.select_dtypes(include=np.number).columns]\n",
        "    yearly_interconnectors = df[numeric_interconnector_cols].resample('Y').sum()\n",
        "    yearly_interconnectors.plot.area(ax=ax7, alpha=0.7)\n",
        "    ax7.set_title('Yearly Interconnector Flows')\n",
        "    ax7.set_xlabel('Year')\n",
        "    ax7.set_ylabel('Total Flow (GWh equivalent)')\n",
        "    ax7.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax7.grid(True, alpha=0.3)\n",
        "\n",
        "    # 8. Seasonal patterns\n",
        "    ax8 = plt.subplot(3, 3, 8)\n",
        "    # Convert season from dummy to numerical if needed for plotting\n",
        "    # Assuming season is handled by dummy variables or numerical encoding now\n",
        "    if 'season_Winter' in df.columns and 'season_Summer' in df.columns: # Check for dummy vars\n",
        "        # Plotting the average demand for each season based on dummy variables\n",
        "        # This requires reconstructing the season from dummies or using the numerical 'season' column if available\n",
        "        # Since create_comprehensive_features now returns 'season' as numeric (1-4),\n",
        "        # we can use that directly.\n",
        "        season_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Autumn'}\n",
        "        seasonal_avg = df.groupby(['season', 'hour'])['england_wales_demand'].mean().unstack(level=0)\n",
        "        if not seasonal_avg.empty:\n",
        "            seasonal_avg.rename(columns=season_map, inplace=True)\n",
        "            seasonal_avg.plot(ax=ax8, linewidth=2)\n",
        "        else:\n",
        "            ax8.text(0.5, 0.5, 'No seasonal data to plot', horizontalalignment='center', verticalalignment='center', transform=ax8.transAxes)\n",
        "\n",
        "    else:\n",
        "        ax8.text(0.5, 0.5, 'Seasonal dummy variables not found or season column is missing', horizontalalignment='center', verticalalignment='center', transform=ax8.transAxes)\n",
        "\n",
        "    ax8.set_title('Seasonal Demand Patterns')\n",
        "    ax8.set_xlabel('Hour of Day')\n",
        "    ax8.set_ylabel('Demand (MW)')\n",
        "    ax8.legend(title='Season')\n",
        "    ax8.grid(True, alpha=0.3)\n",
        "\n",
        "    # 9. Holiday vs non-holiday comparison\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "    holiday_comparison = df.groupby(['is_holiday', 'hour'])['england_wales_demand'].mean().unstack(level=0)\n",
        "    if not holiday_comparison.empty:\n",
        "        holiday_comparison.columns = ['Non-Holiday', 'Holiday']\n",
        "        holiday_comparison.plot(ax=ax9, linewidth=2)\n",
        "    else:\n",
        "        ax9.text(0.5, 0.5, 'No holiday data to plot', horizontalalignment='center', verticalalignment='center', transform=ax9.transAxes)\n",
        "    ax9.set_title('Holiday vs Non-Holiday Demand Patterns')\n",
        "    ax9.set_xlabel('Hour of Day')\n",
        "    ax9.set_ylabel('Demand (MW)')\n",
        "    ax9.legend()\n",
        "    ax9.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print additional insights\n",
        "    print(\"\\n2. KEY INSIGHTS:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Peak demand analysis\n",
        "    peak_demand = df['england_wales_demand'].max()\n",
        "    peak_time = df['england_wales_demand'].idxmax()\n",
        "    print(f\"Peak Demand: {peak_demand:,.0f} MW at {peak_time}\")\n",
        "\n",
        "    # Minimum demand\n",
        "    min_demand = df['england_wales_demand'].min()\n",
        "    min_time = df['england_wales_demand'].idxmin()\n",
        "    print(f\"Minimum Demand: {min_demand:,.0f} MW at {min_time}\")\n",
        "\n",
        "    # Demand variability\n",
        "    daily_peak = df.resample('D')['england_wales_demand'].max().mean()\n",
        "    daily_min = df.resample('D')['england_wales_demand'].min().mean()\n",
        "    print(f\"Average Daily Peak: {daily_peak:,.0f} MW\")\n",
        "    print(f\"Average Daily Minimum: {daily_min:,.0f} MW\")\n",
        "    print(f\"Average Daily Range: {daily_peak - daily_min:,.0f} MW\")\n",
        "\n",
        "    # Renewable penetration\n",
        "    max_solar_pen = df['solar_penetration'].max() * 100 if 'solar_penetration' in df.columns else 0\n",
        "    max_wind_pen = df['wind_penetration'].max() * 100 if 'wind_penetration' in df.columns else 0\n",
        "    print(f\"Maximum Solar Penetration: {max_solar_pen:.1f}%\")\n",
        "    print(f\"Maximum Wind Penetration: {max_wind_pen:.1f}%\")\n",
        "\n",
        "    # Growth trends\n",
        "    first_year_demand = df.loc['2009']['england_wales_demand'].mean()\n",
        "    last_year_demand = df.loc['2023']['england_wales_demand'].mean()\n",
        "    growth = ((last_year_demand - first_year_demand) / first_year_demand) * 100\n",
        "    print(f\"\\nDemand Growth 2009-2023: {growth:.1f}%\")\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Perform EDA\n",
        "fig = perform_comprehensive_eda(demand_features)"
      ],
      "metadata": {
        "id": "tWw3tXDohkbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def train_evaluate_models(X_train_scaled, X_test_scaled, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate multiple forecasting models\n",
        "    \"\"\"\n",
        "    print(\"\\n=== TRAINING MODELS ===\\n\")\n",
        "\n",
        "    # Define models\n",
        "    models = {\n",
        "        'XGBoost': xgb.XGBRegressor(\n",
        "            n_estimators=200,\n",
        "            max_depth=8,\n",
        "            learning_rate=0.05,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbosity=0\n",
        "        ),\n",
        "        'Random Forest': RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            min_samples_split=5,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=5,\n",
        "            random_state=42\n",
        "        ),\n",
        "        'Ridge Regression': Ridge(alpha=1.0, random_state=42),\n",
        "        'Lasso Regression': Lasso(alpha=0.01, random_state=42, max_iter=5000),\n",
        "        'Neural Network': MLPRegressor(\n",
        "            hidden_layer_sizes=(100, 50),\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            max_iter=500,\n",
        "            random_state=42\n",
        "        )\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    predictions = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"Training {name}...\")\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Calculate metrics\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        # Calculate accuracy within tolerances\n",
        "        tolerance_5pct = np.mean(np.abs((y_test - y_pred) / y_test) <= 0.05) * 100\n",
        "        tolerance_2pct = np.mean(np.abs((y_test - y_pred) / y_test) <= 0.02) * 100\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            'MAE': mae,\n",
        "            'RMSE': rmse,\n",
        "            'MAPE': mape,\n",
        "            'R2': r2,\n",
        "            'Within 5%': tolerance_5pct,\n",
        "            'Within 2%': tolerance_2pct,\n",
        "            'model': model\n",
        "        }\n",
        "\n",
        "        predictions[name] = y_pred\n",
        "\n",
        "        print(f\"  MAE: {mae:,.0f} MW | RMSE: {rmse:,.0f} MW | MAPE: {mape:.2f}% | R²: {r2:.3f}\")\n",
        "        print(f\"  Within 5%: {tolerance_5pct:.1f}% | Within 2%: {tolerance_2pct:.1f}%\")\n",
        "        print()\n",
        "\n",
        "    # Create comparison DataFrame\n",
        "    results_df = pd.DataFrame(results).T\n",
        "    results_df = results_df[['MAE', 'RMSE', 'MAPE', 'R2', 'Within 5%', 'Within 2%']]\n",
        "\n",
        "    print(\"\\n=== MODEL COMPARISON ===\")\n",
        "    print(\"-\" * 80)\n",
        "    print(results_df.round(3))\n",
        "\n",
        "    return results, predictions, results_df\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "TARGET = 'england_wales_demand'\n",
        "X = demand_features.drop(columns=[TARGET])\n",
        "y = demand_features[TARGET]\n",
        "\n",
        "# Define the split point for time series\n",
        "split_date = '2023-01-01'\n",
        "X_train = X.loc[X.index < split_date]\n",
        "y_train = y.loc[y.index < split_date]\n",
        "X_test = X.loc[X.index >= split_date]\n",
        "y_test = y.loc[y.index >= split_date]\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert scaled arrays back to DataFrames for model compatibility and feature tracking\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "# Train and evaluate models\n",
        "results, predictions, results_df = train_evaluate_models(\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC11gi4DhoY0",
        "outputId": "efefc708-0f85-48d4-ed11-1afc9b88d6eb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (245424, 72), y_train shape: (245424,)\n",
            "X_test shape: (33840, 72), y_test shape: (33840,)\n",
            "\n",
            "=== TRAINING MODELS ===\n",
            "\n",
            "Training XGBoost...\n",
            "  MAE: 149 MW | RMSE: 201 MW | MAPE: 0.65% | R²: 0.999\n",
            "  Within 5%: 99.8% | Within 2%: 97.6%\n",
            "\n",
            "Training Random Forest...\n",
            "  MAE: 205 MW | RMSE: 274 MW | MAPE: 0.88% | R²: 0.997\n",
            "  Within 5%: 99.8% | Within 2%: 91.9%\n",
            "\n",
            "Training Gradient Boosting...\n",
            "  MAE: 194 MW | RMSE: 258 MW | MAPE: 0.84% | R²: 0.998\n",
            "  Within 5%: 99.6% | Within 2%: 93.4%\n",
            "\n",
            "Training Ridge Regression...\n",
            "  MAE: 0 MW | RMSE: 0 MW | MAPE: 0.00% | R²: 1.000\n",
            "  Within 5%: 100.0% | Within 2%: 100.0%\n",
            "\n",
            "Training Lasso Regression...\n",
            "  MAE: 248 MW | RMSE: 409 MW | MAPE: 1.06% | R²: 0.994\n",
            "  Within 5%: 99.3% | Within 2%: 73.3%\n",
            "\n",
            "Training Neural Network...\n",
            "  MAE: 32 MW | RMSE: 48 MW | MAPE: 0.14% | R²: 1.000\n",
            "  Within 5%: 100.0% | Within 2%: 99.8%\n",
            "\n",
            "\n",
            "=== MODEL COMPARISON ===\n",
            "--------------------------------------------------------------------------------\n",
            "                          MAE        RMSE      MAPE        R2  Within 5%  \\\n",
            "XGBoost            149.015656  200.940863  0.646059  0.998631  99.769504   \n",
            "Random Forest      205.140383  273.518285   0.87756  0.997463  99.816785   \n",
            "Gradient Boosting  193.555823  257.974586  0.841057  0.997743  99.618794   \n",
            "Ridge Regression     0.262133    0.333555  0.001139       1.0      100.0   \n",
            "Lasso Regression   248.126767  408.763587  1.063715  0.994334   99.28487   \n",
            "Neural Network      31.755098   48.018252  0.141927  0.999922      100.0   \n",
            "\n",
            "                   Within 2%  \n",
            "XGBoost            97.576832  \n",
            "Random Forest      91.855792  \n",
            "Gradient Boosting  93.427896  \n",
            "Ridge Regression       100.0  \n",
            "Lasso Regression   73.327423  \n",
            "Neural Network     99.834515  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_forecast_results(y_test, predictions, results_df, sample_days=7):\n",
        "    \"\"\"\n",
        "    Visualize forecast results and model performance\n",
        "    \"\"\"\n",
        "    print(\"\\n=== VISUALIZING RESULTS ===\\n\")\n",
        "\n",
        "    # Convert predictions to DataFrame\n",
        "    pred_df = pd.DataFrame(predictions, index=y_test.index)\n",
        "    pred_df['Actual'] = y_test\n",
        "\n",
        "    # Sample a week for detailed visualization\n",
        "    sample_start = pred_df.index[0]\n",
        "    sample_end = sample_start + pd.Timedelta(days=sample_days)\n",
        "    sample_data = pred_df.loc[sample_start:sample_end]\n",
        "\n",
        "    # Create visualizations\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(18, 15))\n",
        "\n",
        "    # 1. Time series comparison (best model)\n",
        "    best_model = results_df['MAPE'].idxmin()\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.plot(sample_data.index, sample_data['Actual'],\n",
        "             label='Actual', linewidth=2, color='black')\n",
        "    ax1.plot(sample_data.index, sample_data[best_model],\n",
        "             label=f'{best_model} Prediction', linewidth=1.5,\n",
        "             linestyle='--', alpha=0.8)\n",
        "    ax1.fill_between(sample_data.index,\n",
        "                     sample_data['Actual'] * 0.97,\n",
        "                     sample_data['Actual'] * 1.03,\n",
        "                     alpha=0.2, color='gray', label='±3% Band')\n",
        "    ax1.set_title(f'Best Model ({best_model}) Forecast vs Actual\\n(Sample Week)')\n",
        "    ax1.set_ylabel('Demand (MW)')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
        "\n",
        "    # 2. Error distribution\n",
        "    ax2 = axes[0, 1]\n",
        "    errors = {}\n",
        "    for model in predictions.keys():\n",
        "        errors[model] = (predictions[model] - y_test) / y_test * 100\n",
        "\n",
        "    error_df = pd.DataFrame(errors)\n",
        "    error_df.plot.kde(ax=ax2, linewidth=2)\n",
        "    ax2.axvline(0, color='black', linestyle='--', alpha=0.5, linewidth=1)\n",
        "    ax2.set_title('Error Distribution by Model')\n",
        "    ax2.set_xlabel('Percentage Error (%)')\n",
        "    ax2.set_ylabel('Density')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.legend()\n",
        "\n",
        "    # 3. Scatter plot of predictions vs actual\n",
        "    ax3 = axes[1, 0]\n",
        "    for model in ['XGBoost', 'Random Forest', 'Gradient Boosting']:\n",
        "        if model in predictions:\n",
        "            ax3.scatter(y_test, predictions[model],\n",
        "                       alpha=0.1, s=10, label=model)\n",
        "    ax3.plot([y_test.min(), y_test.max()],\n",
        "             [y_test.min(), y_test.max()],\n",
        "             'k--', linewidth=2, label='Perfect Prediction')\n",
        "    ax3.set_title('Predictions vs Actual (All Test Data)')\n",
        "    ax3.set_xlabel('Actual Demand (MW)')\n",
        "    ax3.set_ylabel('Predicted Demand (MW)')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Model performance comparison\n",
        "    ax4 = axes[1, 1]\n",
        "    metrics_to_plot = ['MAE', 'RMSE', 'MAPE']\n",
        "    metrics_df = results_df[metrics_to_plot].copy()\n",
        "    # Normalize for better visualization\n",
        "    metrics_normalized = metrics_df / metrics_df.max()\n",
        "\n",
        "    x = np.arange(len(metrics_df.index))\n",
        "    width = 0.25\n",
        "\n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        offset = width * (i - 1)\n",
        "        ax4.bar(x + offset, metrics_normalized[metric],\n",
        "                width, label=metric)\n",
        "\n",
        "    ax4.set_title('Model Performance Comparison (Normalized)')\n",
        "    ax4.set_xlabel('Model')\n",
        "    ax4.set_ylabel('Normalized Metric (Lower is Better)')\n",
        "    ax4.set_xticks(x)\n",
        "    ax4.set_xticklabels(metrics_df.index, rotation=45)\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # 5. Feature importance (XGBoost)\n",
        "    ax5 = axes[2, 0]\n",
        "    if 'XGBoost' in results:\n",
        "        xgb_model = results['XGBoost']['model']\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': features,\n",
        "            'importance': xgb_model.feature_importances_\n",
        "        }).sort_values('importance', ascending=True).tail(15)\n",
        "\n",
        "        ax5.barh(feature_importance['feature'],\n",
        "                feature_importance['importance'])\n",
        "        ax5.set_title('Top 15 Feature Importances (XGBoost)')\n",
        "        ax5.set_xlabel('Importance Score')\n",
        "        ax5.grid(True, alpha=0.3)\n",
        "\n",
        "    # 6. Prediction error by time of day\n",
        "    ax6 = axes[2, 1]\n",
        "    error_by_hour = pd.DataFrame({\n",
        "        'hour': y_test.index.hour,\n",
        "        'error_pct': np.abs((predictions[best_model] - y_test) / y_test * 100)\n",
        "    })\n",
        "    hourly_error = error_by_hour.groupby('hour')['error_pct'].mean()\n",
        "\n",
        "    ax6.bar(hourly_error.index, hourly_error.values)\n",
        "    ax6.set_title(f'Average Prediction Error by Hour of Day\\n({best_model} Model)')\n",
        "    ax6.set_xlabel('Hour of Day')\n",
        "    ax6.set_ylabel('Mean Absolute Percentage Error (%)')\n",
        "    ax6.set_xticks(range(0, 24, 2))\n",
        "    ax6.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed performance analysis\n",
        "    print(\"DETAILED PERFORMANCE ANALYSIS:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    best_overall"
      ],
      "metadata": {
        "id": "TkBjMVHAiAPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #========================================"
      ],
      "metadata": {
        "id": "xkZE9JETiOm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== HANDLING DUPLICATES ===\\n\")\n",
        "\n",
        "# Check for duplicates\n",
        "duplicate_mask = demand.index.duplicated(keep=False)\n",
        "duplicates = demand[duplicate_mask]\n",
        "\n",
        "print(f\"Found {len(duplicates)} duplicate timestamps\")\n",
        "if len(duplicates) > 0:\n",
        "    print(\"\\nSample duplicates:\")\n",
        "    print(duplicates.head(10))\n",
        "\n",
        "    # Remove duplicates, keeping the first occurrence\n",
        "    demand = demand[~demand.index.duplicated(keep='first')]\n",
        "    print(f\"\\nData shape after removing duplicates: {demand.shape}\")"
      ],
      "metadata": {
        "id": "w6pYWVGhKHOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_comprehensive_features_fixed(df):\n",
        "    \"\"\"\n",
        "    Create comprehensive features for electricity demand forecasting\n",
        "    \"\"\"\n",
        "    df_feat = df.copy()\n",
        "\n",
        "    # 1. Temporal Features\n",
        "    df_feat['hour'] = df_feat.index.hour\n",
        "    df_feat['minute'] = df_feat.index.minute\n",
        "    df_feat['half_hour_period'] = df_feat['hour'] * 2 + (df_feat['minute'] // 30)\n",
        "    df_feat['day_of_week'] = df_feat.index.dayofweek\n",
        "    df_feat['day_of_month'] = df_feat.index.day\n",
        "    df_feat['month'] = df_feat.index.month\n",
        "    df_feat['quarter'] = df_feat.index.quarter\n",
        "    df_feat['year'] = df_feat.index.year\n",
        "    df_feat['day_of_year'] = df_feat.index.dayofyear\n",
        "    df_feat['week_of_year'] = df_feat.index.isocalendar().week\n",
        "\n",
        "    # 2. Calendar Features\n",
        "    df_feat['is_weekend'] = (df_feat['day_of_week'] >= 5).astype(int)\n",
        "    df_feat['is_weekday'] = (df_feat['day_of_week'] < 5).astype(int)\n",
        "    df_feat['is_working_day'] = ((df_feat['day_of_week'] < 5) & (df_feat['is_holiday'] == 0)).astype(int)\n",
        "\n",
        "    # Special periods\n",
        "    df_feat['is_morning_peak'] = ((df_feat['hour'] >= 7) & (df_feat['hour'] <= 10)).astype(int)\n",
        "    df_feat['is_evening_peak'] = ((df_feat['hour'] >= 16) & (df_feat['hour'] <= 20)).astype(int)\n",
        "    df_feat['is_overnight'] = ((df_feat['hour'] >= 0) & (df_feat['hour'] <= 5)).astype(int)\n",
        "\n",
        "    # 3. Calculate Net Demand\n",
        "    df_feat['embedded_total_generation'] = df_feat['embedded_wind_generation'] + df_feat['embedded_solar_generation']\n",
        "    df_feat['net_demand'] = df_feat['england_wales_demand'] - df_feat['embedded_total_generation']\n",
        "\n",
        "    # 4. Capacity Factors\n",
        "    df_feat['wind_capacity_factor'] = np.where(\n",
        "        df_feat['embedded_wind_capacity'] > 0,\n",
        "        df_feat['embedded_wind_generation'] / df_feat['embedded_wind_capacity'],\n",
        "        0\n",
        "    )\n",
        "    df_feat['solar_capacity_factor'] = np.where(\n",
        "        df_feat['embedded_solar_capacity'] > 0,\n",
        "        df_feat['embedded_solar_generation'] / df_feat['embedded_solar_capacity'],\n",
        "        0\n",
        "    )\n",
        "\n",
        "    # 5. Interconnector Analysis\n",
        "    interconnector_cols = [col for col in df.columns if '_flow' in col]\n",
        "\n",
        "    # Fill missing values in interconnectors\n",
        "    for col in interconnector_cols:\n",
        "        # Use forward fill and backward fill (updated syntax)\n",
        "        df_feat[col] = df_feat[col].ffill().bfill().fillna(0)\n",
        "\n",
        "    # Calculate interconnector statistics\n",
        "    df_feat['total_interconnector_flow'] = df_feat[interconnector_cols].sum(axis=1)\n",
        "    df_feat['interconnector_imports'] = df_feat[interconnector_cols].clip(lower=0).sum(axis=1)\n",
        "    df_feat['interconnector_exports'] = df_feat[interconnector_cols].clip(upper=0).abs().sum(axis=1)\n",
        "\n",
        "    # 6. Cyclical Encoding for Time Features\n",
        "    df_feat['hour_sin'] = np.sin(2 * np.pi * df_feat['hour'] / 24)\n",
        "    df_feat['hour_cos'] = np.cos(2 * np.pi * df_feat['hour'] / 24)\n",
        "    df_feat['day_of_week_sin'] = np.sin(2 * np.pi * df_feat['day_of_week'] / 7)\n",
        "    df_feat['day_of_week_cos'] = np.cos(2 * np.pi * df_feat['day_of_week'] / 7)\n",
        "    df_feat['month_sin'] = np.sin(2 * np.pi * df_feat['month'] / 12)\n",
        "    df_feat['month_cos'] = np.cos(2 * np.pi * df_feat['month'] / 12)\n",
        "\n",
        "    # 7. Lag Features (Autoregressive)\n",
        "    df_feat['demand_lag_1'] = df_feat['england_wales_demand'].shift(1)\n",
        "    df_feat['demand_lag_2'] = df_feat['england_wales_demand'].shift(2)\n",
        "    df_feat['demand_lag_48'] = df_feat['england_wales_demand'].shift(48)\n",
        "    df_feat['demand_lag_336'] = df_feat['england_wales_demand'].shift(336)\n",
        "    df_feat['net_demand_lag_48'] = df_feat['net_demand'].shift(48)\n",
        "\n",
        "    # 8. Rolling Statistics\n",
        "    df_feat['demand_rolling_24h_mean'] = df_feat['england_wales_demand'].rolling(window=48, min_periods=1).mean()\n",
        "    df_feat['demand_rolling_24h_std'] = df_feat['england_wales_demand'].rolling(window=48, min_periods=1).std()\n",
        "    df_feat['demand_rolling_7d_mean'] = df_feat['england_wales_demand'].rolling(window=336, min_periods=1).mean()\n",
        "    df_feat['demand_rolling_7d_std'] = df_feat['england_wales_demand'].rolling(window=336, min_periods=1).std()\n",
        "\n",
        "    # 9. Rate of Change\n",
        "    df_feat['demand_change_1h'] = df_feat['england_wales_demand'].diff(2)\n",
        "    df_feat['demand_change_24h'] = df_feat['england_wales_demand'].diff(48)\n",
        "\n",
        "    # 10. Penetration Rates\n",
        "    # Avoid division by zero\n",
        "    df_feat['wind_penetration'] = np.where(\n",
        "        df_feat['england_wales_demand'] > 0,\n",
        "        df_feat['embedded_wind_generation'] / df_feat['england_wales_demand'],\n",
        "        0\n",
        "    )\n",
        "    df_feat['solar_penetration'] = np.where(\n",
        "        df_feat['england_wales_demand'] > 0,\n",
        "        df_feat['embedded_solar_generation'] / df_feat['england_wales_demand'],\n",
        "        0\n",
        "    )\n",
        "    df_feat['total_renewable_penetration'] = np.where(\n",
        "        df_feat['england_wales_demand'] > 0,\n",
        "        (df_feat['embedded_wind_generation'] + df_feat['embedded_solar_generation']) / df_feat['england_wales_demand'],\n",
        "        0\n",
        "    )\n",
        "\n",
        "    # 11. Season Indicators (as numeric, not categorical for now)\n",
        "    # 1: Winter, 2: Spring, 3: Summer, 4: Autumn\n",
        "    def get_season_numeric(month):\n",
        "        if month in [12, 1, 2]:\n",
        "            return 1  # Winter\n",
        "        elif month in [3, 4, 5]:\n",
        "            return 2  # Spring\n",
        "        elif month in [6, 7, 8]:\n",
        "            return 3  # Summer\n",
        "        else:\n",
        "            return 4  # Autumn\n",
        "\n",
        "    df_feat['season'] = df_feat['month'].apply(get_season_numeric)\n",
        "\n",
        "    # 12. Time of Day Categories (as numeric)\n",
        "    def get_time_of_day_numeric(hour):\n",
        "        if 0 <= hour < 6:\n",
        "            return 1  # Night\n",
        "        elif 6 <= hour < 9:\n",
        "            return 2  # Morning Peak\n",
        "        elif 9 <= hour < 16:\n",
        "            return 3  # Day\n",
        "        elif 16 <= hour < 19:\n",
        "            return 4  # Evening Peak\n",
        "        else:\n",
        "            return 5  # Evening\n",
        "\n",
        "    df_feat['time_of_day'] = df_feat['hour'].apply(get_time_of_day_numeric)\n",
        "\n",
        "    # Fill any remaining NaN values\n",
        "    df_feat = df_feat.ffill().bfill().fillna(0)\n",
        "\n",
        "    print(f\"Total features created: {len(df_feat.columns)}\")\n",
        "    return df_feat\n",
        "\n",
        "# Apply fixed feature engineering\n",
        "print(\"\\n=== CREATING FEATURES (FIXED) ===\")\n",
        "demand_features = create_comprehensive_features_fixed(demand)\n",
        "print(f\"Original columns: {len(demand.columns)}\")\n",
        "print(f\"Enhanced features: {len(demand_features.columns)}\")\n",
        "\n",
        "# Display the new features\n",
        "print(\"\\nNew features created:\")\n",
        "new_features = [col for col in demand_features.columns if col not in demand.columns]\n",
        "print(f\"Total new features: {len(new_features)}\")\n",
        "print(\"Sample of new features:\", new_features[:20])"
      ],
      "metadata": {
        "id": "TVXfvJNpLaMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is removed as its functionality is now integrated into cell LmCcJV-0KKI1."
      ],
      "metadata": {
        "id": "TvDK7TXNLaP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_features(df):\n",
        "    df_feat = df.copy()\n",
        "\n",
        "    # --- Temporal\n",
        "    df_feat[\"hour\"] = df_feat.index.hour\n",
        "    df_feat[\"minute\"] = df_feat.index.minute\n",
        "    df_feat[\"half_hour_period\"] = df_feat[\"hour\"] * 2 + (df_feat[\"minute\"] // 30)\n",
        "    df_feat[\"day_of_week\"] = df_feat.index.dayofweek\n",
        "    df_feat[\"day_of_month\"] = df_feat.index.day\n",
        "    df_feat[\"month\"] = df_feat.index.month\n",
        "    df_feat[\"quarter\"] = df_feat.index.quarter\n",
        "    df_feat[\"year\"] = df_feat.index.year\n",
        "    df_feat[\"day_of_year\"] = df_feat.index.dayofyear\n",
        "    df_feat[\"week_of_year\"] = df_feat.index.isocalendar().week.astype(int)\n",
        "\n",
        "    # --- Calendar\n",
        "    df_feat[\"is_weekend\"] = (df_feat[\"day_of_week\"] >= 5).astype(int)\n",
        "    df_feat[\"is_working_day\"] = ((df_feat[\"day_of_week\"] < 5) & (df_feat[\"is_holiday\"] == 0)).astype(int)\n",
        "\n",
        "    df_feat[\"is_morning_peak\"] = ((df_feat[\"hour\"] >= 7) & (df_feat[\"hour\"] <= 10)).astype(int)\n",
        "    df_feat[\"is_evening_peak\"] = ((df_feat[\"hour\"] >= 16) & (df_feat[\"hour\"] <= 20)).astype(int)\n",
        "    df_feat[\"is_overnight\"] = ((df_feat[\"hour\"] >= 0) & (df_feat[\"hour\"] <= 5)).astype(int)\n",
        "\n",
        "    # --- Net demand\n",
        "    df_feat[\"embedded_total_generation\"] = (\n",
        "        df_feat[\"embedded_wind_generation\"].fillna(0) + df_feat[\"embedded_solar_generation\"].fillna(0)\n",
        "    )\n",
        "    df_feat[\"net_demand\"] = df_feat[\"england_wales_demand\"] - df_feat[\"embedded_total_generation\"]\n",
        "\n",
        "    # --- Capacity factors\n",
        "    df_feat[\"wind_capacity_factor\"] = np.where(\n",
        "        df_feat[\"embedded_wind_capacity\"] > 0,\n",
        "        df_feat[\"embedded_wind_generation\"] / df_feat[\"embedded_wind_capacity\"],\n",
        "        0\n",
        "    )\n",
        "    df_feat[\"solar_capacity_factor\"] = np.where(\n",
        "        df_feat[\"embedded_solar_capacity\"] > 0,\n",
        "        df_feat[\"embedded_solar_generation\"] / df_feat[\"embedded_solar_capacity\"],\n",
        "        0\n",
        "    )\n",
        "\n",
        "    # --- Interconnectors\n",
        "    interconnector_cols = [c for c in df_feat.columns if c.endswith(\"_flow\")]\n",
        "    for c in interconnector_cols:\n",
        "        df_feat[c] = df_feat[c].ffill().bfill().fillna(0)\n",
        "\n",
        "    df_feat[\"total_interconnector_flow\"] = df_feat[interconnector_cols].sum(axis=1)\n",
        "    df_feat[\"interconnector_imports\"] = df_feat[interconnector_cols].clip(lower=0).sum(axis=1)\n",
        "    df_feat[\"interconnector_exports\"] = df_feat[interconnector_cols].clip(upper=0).abs().sum(axis=1)\n",
        "\n",
        "    # --- Cyclical encodings\n",
        "    df_feat[\"hour_sin\"] = np.sin(2 * np.pi * df_feat[\"hour\"] / 24)\n",
        "    df_feat[\"hour_cos\"] = np.cos(2 * np.pi * df_feat[\"hour\"] / 24)\n",
        "    df_feat[\"day_of_week_sin\"] = np.sin(2 * np.pi * df_feat[\"day_of_week\"] / 7)\n",
        "    df_feat[\"day_of_week_cos\"] = np.cos(2 * np.pi * df_feat[\"day_of_week\"] / 7)\n",
        "    df_feat[\"month_sin\"] = np.sin(2 * np.pi * df_feat[\"month\"] / 12)\n",
        "    df_feat[\"month_cos\"] = np.cos(2 * np.pi * df_feat[\"month\"] / 12)\n",
        "\n",
        "    # --- Lags (half-hourly)\n",
        "    df_feat[\"demand_lag_1\"] = df_feat[\"england_wales_demand\"].shift(1)\n",
        "    df_feat[\"demand_lag_48\"] = df_feat[\"england_wales_demand\"].shift(48)     # 24h\n",
        "    df_feat[\"demand_lag_336\"] = df_feat[\"england_wales_demand\"].shift(336)   # 7d\n",
        "    df_feat[\"net_demand_lag_48\"] = df_feat[\"net_demand\"].shift(48)\n",
        "\n",
        "    # --- Rolling stats (LEAKAGE-SAFE: shift by 1)\n",
        "    df_feat[\"demand_roll_24h_mean\"] = df_feat[\"england_wales_demand\"].rolling(48).mean().shift(1)\n",
        "    df_feat[\"demand_roll_7d_mean\"] = df_feat[\"england_wales_demand\"].rolling(336).mean().shift(1)\n",
        "\n",
        "    # --- Change features (optional leakage-safe)\n",
        "    df_feat[\"demand_change_1h\"] = df_feat[\"england_wales_demand\"].diff(2).shift(1)\n",
        "    df_feat[\"demand_change_24h\"] = df_feat[\"england_wales_demand\"].diff(48).shift(1)\n",
        "\n",
        "    # --- Penetration\n",
        "    demand_safe = df_feat[\"england_wales_demand\"].replace(0, np.nan)\n",
        "    df_feat[\"wind_penetration\"] = (df_feat[\"embedded_wind_generation\"] / demand_safe).fillna(0)\n",
        "    df_feat[\"solar_penetration\"] = (df_feat[\"embedded_solar_generation\"] / demand_safe).fillna(0)\n",
        "\n",
        "    # Fill remaining NaNs after lags/rollings\n",
        "    df_feat = df_feat.dropna()\n",
        "\n",
        "    return df_feat\n"
      ],
      "metadata": {
        "id": "GQWB49XKLaV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "jcF6D0hZWJbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# !pip install optuna # Commenting out as it's installed in a separate cell now\n",
        "\n",
        "def objective(trial):\n",
        "    # Hyperparameter search space\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 2000),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "    }\n",
        "\n",
        "    # Time-series CV (walk-forward)\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "    fold_scores = []\n",
        "    for train_idx, valid_idx in tscv.split(X_train_scaled, y_train):\n",
        "        X_tr, X_val = X_train_scaled.iloc[train_idx], X_train_scaled.iloc[valid_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
        "\n",
        "        model = xgb.XGBRegressor(**params)\n",
        "\n",
        "        model.fit(\n",
        "            X_tr,\n",
        "            y_tr,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=50,\n",
        "        )\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "\n",
        "        # Choose ONE metric to optimize\n",
        "        mape = mean_absolute_percentage_error(y_val, preds)\n",
        "        fold_scores.append(mape)\n",
        "\n",
        "    return float(np.mean(fold_scores))\n",
        "\n",
        "# Create the Optuna study and optimize\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
        "\n",
        "# Print the best trial's parameters and the best value achieved\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  Value (MAPE): {trial.value:.6f}\")\n",
        "print(\"  Params:\")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ],
      "metadata": {
        "id": "WIT50liwLaZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error\n",
        "\n",
        "def objective(trial):\n",
        "    # Hyperparameter search space\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 2000),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "        \"random_state\": 42,\n",
        "        \"n_jobs\": -1,\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "    }\n",
        "\n",
        "    # Time-series CV (walk-forward)\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "    fold_scores = []\n",
        "    for train_idx, valid_idx in tscv.split(X_train, y_train):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
        "\n",
        "        model = xgb.XGBRegressor(**params)\n",
        "\n",
        "        model.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=50\n",
        "        )\n",
        "\n",
        "        preds = model.predict(X_val)\n",
        "\n",
        "        # Choose ONE metric to optimize\n",
        "        mape = mean_absolute_percentage_error(y_val, preds)\n",
        "        fold_scores.append(mape)\n",
        "\n",
        "    return float(np.mean(fold_scores))\n",
        "\n",
        "# Create the Optuna study and optimize\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
        "\n",
        "# Print the best trial's parameters and the best value achieved\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  Value (MAPE): {trial.value:.6f}\")\n",
        "print(\"  Params:\")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n"
      ],
      "metadata": {
        "id": "JI8_CKTqV6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#==============================="
      ],
      "metadata": {
        "id": "oM-Bde30fUV_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTzPOYVDhuBF",
        "outputId": "52474586-88cd-410d-a452-92ebb33cdde5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.12/dist-packages (from pycaret) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (4.67.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.12/dist-packages (from pycaret) (1.26.4)\n",
            "Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (2.1.4)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.12/dist-packages (from pycaret) (3.1.6)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from pycaret) (1.11.4)\n",
            "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (1.4.2)\n",
            "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from pycaret) (2.0.6)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (0.14.1)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (2.7.0)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (4.6.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from pycaret) (2.32.4)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from pycaret) (3.0.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (8.7.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from pycaret) (3.1.2)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: matplotlib<3.8.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (3.7.5)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.12/dist-packages (from pycaret) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (5.24.1)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from pycaret) (1.2.0)\n",
            "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.12/dist-packages (from pycaret) (0.15)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.12/dist-packages (from pycaret) (0.11.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pycaret) (0.14.6)\n",
            "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.12/dist-packages (from pycaret) (0.26.0)\n",
            "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from pycaret) (1.1.3)\n",
            "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pycaret) (2.0.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.12/dist-packages (from pycaret) (3.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from sktime==0.26.0->pycaret) (25.0)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.12/dist-packages (from sktime==0.26.0->pycaret) (0.7.8)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category-encoders>=2.4.0->pycaret) (1.0.2)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (0.1.5)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (3.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.23.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.5->pycaret) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.16)\n",
            "Requirement already satisfied: choreographer>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from kaleido>=0.2.1->pycaret) (1.2.1)\n",
            "Requirement already satisfied: logistro>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from kaleido>=0.2.1->pycaret) (2.0.1)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from kaleido>=0.2.1->pycaret) (3.11.5)\n",
            "Requirement already satisfied: pytest-timeout>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kaleido>=0.2.1->pycaret) (2.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret) (1.4.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.8.0->pycaret) (2.9.0.post0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.2.0->pycaret) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.2.0->pycaret) (4.26.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.2.0->pycaret) (5.9.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.55.0->pycaret) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.2.0->pycaret) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.2.0->pycaret) (2025.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.14.0->pycaret) (9.1.2)\n",
            "Requirement already satisfied: dash>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.4.0)\n",
            "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.4.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima>=2.0.4->pycaret) (3.0.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from pmdarima>=2.0.4->pycaret) (2.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->pycaret) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->pycaret) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.27.1->pycaret) (2026.1.4)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.12/dist-packages (from choreographer>=1.1.1->kaleido>=0.2.1->pycaret) (3.20.2)\n",
            "Requirement already satisfied: Flask<3.2,>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from dash>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug<3.2 in /usr/local/lib/python3.12/dist-packages (from dash>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (3.1.5)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from dash>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (4.15.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.12/dist-packages (from dash>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (1.4.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from dash>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (7.4.9)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.30.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.14)\n",
            "Requirement already satisfied: pytest>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from pytest-timeout>=2.4.0->kaleido>=0.2.1->pycaret) (8.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib<3.8.0->pycaret) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.7)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<3.2,>=1.0.4->dash>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask<3.2,>=1.0.4->dash>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<3.2,>=1.0.4->dash>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (0.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (25.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.1.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.24.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.3)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido>=0.2.1->pycaret) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido>=0.2.1->pycaret) (1.6.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.2.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.8.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.12.1)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.9.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "demand = pd.read_csv(\"historic_demand_2009_2024.csv\")\n",
        "demand[\"settlement_date\"] = pd.to_datetime(demand[\"settlement_date\"], errors=\"coerce\")\n",
        "demand[\"settlement_period\"] = pd.to_numeric(demand[\"settlement_period\"], errors=\"coerce\")\n",
        "\n",
        "demand[\"timestamp\"] = demand[\"settlement_date\"] + pd.to_timedelta((demand[\"settlement_period\"] - 1) * 30, unit=\"m\")\n",
        "demand = demand.dropna(subset=[\"timestamp\"]).set_index(\"timestamp\").sort_index()\n"
      ],
      "metadata": {
        "id": "IOM0XjllfUZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RdK7NWaaf-mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "\n",
        "# Restarting the kernel\n",
        "IPython.Application.instance().kernel.do_shutdown(restart=True)\n"
      ],
      "metadata": {
        "id": "LF0LaxQmhOe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.time_series import *\n",
        "\n",
        "y = demand[[\"england_wales_demand\"]]   # or a Series\n",
        "# Forecast horizon: 48 = next 24 hours (half-hourly)\n",
        "exp = setup(\n",
        "    data=y,\n",
        "    fh=48,\n",
        "    fold=5,                # time-series CV folds\n",
        "    session_id=42,\n",
        "    numeric_imputation_target=\"ffill\",\n",
        ")\n",
        "\n",
        "best = compare_models(sort=\"MASE\")     # or \"MAPE\"/\"RMSE\" depending on your preference\n",
        "tuned = tune_model(best, n_iter=50, optimize=\"MASE\")   # can be \"MAPE\", \"RMSE\"\n",
        "final = finalize_model(tuned)\n",
        "\n",
        "future = predict_model(final, fh=48)\n",
        "print(future.head())\n"
      ],
      "metadata": {
        "id": "m5Ubwm3mfYwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(final, plot=\"forecast\")\n",
        "plot_model(final, plot=\"diagnostics\")\n",
        "plot_model(final, plot=\"decomp\")\n"
      ],
      "metadata": {
        "id": "WBRmQNnefY35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.regression import *\n",
        "\n",
        "# df_features should already be feature engineered\n",
        "# target column is england_wales_demand\n",
        "exp = setup(\n",
        "    data=df_features,\n",
        "    target=\"england_wales_demand\",\n",
        "    fold_strategy=\"timeseries\",\n",
        "    fold=5,\n",
        "    session_id=42,\n",
        "    normalize=True,     # optional\n",
        ")\n",
        "\n",
        "best = compare_models(sort=\"MAE\")\n",
        "tuned = tune_model(best, n_iter=50, optimize=\"MAE\")\n",
        "final = finalize_model(tuned)\n",
        "\n",
        "# Predict on a held-out test set or future feature frame\n",
        "pred = predict_model(final, data=test_df_features)\n",
        "pred.head()\n"
      ],
      "metadata": {
        "id": "TFI9dxYbfqBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bli6GGsEfu1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}